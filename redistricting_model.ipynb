{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import gerrychain\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import gurobipy as gp\n",
    "import csv\n",
    "import time\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from datetime import date\n",
    "from gurobipy import GRB \n",
    "from gerrychain import Graph\n",
    "# Reading in our shapefile\n",
    "fp = \"/Users/patrickcummins/Desktop/Thesis/Data/County Data Files/North_Carolina_State_and_County_Boundary_Polygons/North_Carolina_State_and_County_Boundary_Polygons.shp\"\n",
    "data2 = gpd.read_file(fp)\n",
    "# Reading in demographics information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp2 = \"/Users/patrickcummins/Desktop/Thesis/split_counties.shp\"\n",
    "data = gpd.read_file(fp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_county_names(dataa, county_name):\n",
    "    # Filter the GeoDataFrame for the specific county\n",
    "    county_rows = data[data['County'] == county_name]\n",
    "    # Generate new names based on the number of parts\n",
    "    new_names = [f\"{county_name}{i + 1}\" for i in range(len(county_rows))]\n",
    "    # Assign new names to the 'County' column\n",
    "    data.loc[county_rows.index, 'County'] = new_names\n",
    "\n",
    "# Update names for each divided county\n",
    "divided_counties = ['Wake', 'Mecklenburg']  # List of counties you divided\n",
    "for county in divided_counties:\n",
    "    update_county_names(data, county)\n",
    "\n",
    "# Check the updated GeoDataFrame\n",
    "print(data[['County']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "data.plot(column='County')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from gerrychain import Graph\n",
    "\n",
    "# Load demographic data\n",
    "demographics = pd.read_csv('/Users/patrickcummins/Desktop/Thesis/Data/Demographics.csv')\n",
    "demographics_to_merge = demographics[['County Name', 'Population']]\n",
    "demographics_to_merge = demographics_to_merge.rename(columns={'County Name': 'County', 'Population': 'Population'})\n",
    "demographics_to_merge['Population'] = demographics_to_merge['Population'].str.replace(',', '').astype(int)\n",
    "\n",
    "# Merge demographic data\n",
    "data = data.merge(demographics_to_merge, on='County', how = 'left')\n",
    "data['County'] = data['County'].str.upper()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wake_pop_new = round(float(1189705 / 4))\n",
    "meck_pop_new = round(float(1159791 / 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_counties = ['WAKE1', 'WAKE2', 'WAKE3', 'WAKE4', 'MECKLENBURG1', 'MECKLENBURG2', 'MECKLENBURG3', 'MECKLENBURG4']\n",
    "# Adjust population for split counties\n",
    "split_counties_wake = ['WAKE1', 'WAKE2', 'WAKE3', 'WAKE4']\n",
    "split_counties_meck = 'MECKLENBURG1', 'MECKLENBURG2', 'MECKLENBURG3', 'MECKLENBURG4'\n",
    "data.loc[data['County'].isin(split_counties_wake), 'Population'] = wake_pop_new\n",
    "data.loc[data['County'].isin(split_counties_meck), 'Population'] = meck_pop_new\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load voting data\n",
    "voting = pd.read_csv(\"/Users/patrickcummins/Desktop/Thesis/Data/Voting.csv\")\n",
    "voting = voting.iloc[1:-1]\n",
    "voting = voting.rename(columns={'Unnamed: 4': 'Other Affiliation'})\n",
    "\n",
    "# Merge voting data\n",
    "data = data.merge(voting, on='County', how = 'left')\n",
    "\n",
    "# Adjust voting counts for split counties\n",
    "voting_columns = ['Democratic', 'Republican', 'Total']\n",
    "for column in voting_columns:\n",
    "    data.loc[data['County'].isin(split_counties), column] /= 4\n",
    "# Convert the GeoDataFrame to a GerryChain Graph\n",
    "graph = Graph.from_geodataframe(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting.loc[voting['County'] == 'MECKLENBURG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wake_dems = round(float(286077 / 4))\n",
    "wake_reps = round(float(176234 / 4))\n",
    "wake_total = round(float(821613 / 4))\n",
    "wake_other = round(float(359302 / 4))\n",
    "\n",
    "meck_dems = round(float(322505 / 4))\n",
    "meck_reps = round(float(155784 / 4))\n",
    "meck_total = round(float(788310 / 4))\n",
    "meck_other = round(float(310021 / 4))\n",
    "\n",
    "data.loc[data['County'].isin(split_counties_wake), 'Democratic'] = wake_dems\n",
    "data.loc[data['County'].isin(split_counties_wake), 'Republican'] = wake_reps\n",
    "data.loc[data['County'].isin(split_counties_wake), 'Total'] = wake_total\n",
    "data.loc[data['County'].isin(split_counties_wake), 'Other Affiliation'] = wake_other\n",
    "\n",
    "data.loc[data['County'].isin(split_counties_meck), 'Democratic'] = meck_dems\n",
    "data.loc[data['County'].isin(split_counties_meck), 'Republican'] = meck_reps\n",
    "data.loc[data['County'].isin(split_counties_meck), 'Total'] = meck_total\n",
    "data.loc[data['County'].isin(split_counties_meck), 'Other Affiliation'] = meck_other\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the GeoDataFrame to a GerryChain Graph\n",
    "graph = Graph.from_geodataframe(data)\n",
    "# Add population data to the county nodes\n",
    "for node in graph.nodes():\n",
    "    # Match the node with the geodataframe index\n",
    "    graph.nodes[node]['population'] = data.loc[node, 'Population']\n",
    "    graph.nodes[node]['county'] = data.loc[node, 'County']\n",
    "    graph.nodes[node]['geoid'] = data.loc[node, 'OBJECTID']\n",
    "    graph.nodes[node]['num_democrats'] = data.loc[node, 'Democratic']\n",
    "    graph.nodes[node]['num_republicans'] = data.loc[node, 'Republican']\n",
    "    graph.nodes[node]['voting_population'] = data.loc[node, 'Total']\n",
    "    # create model \n",
    "deviation = 0.01\n",
    "\n",
    "import math\n",
    "k = 4\n",
    "total_population = sum(graph.nodes[node]['Population'] for node in graph.nodes)\n",
    "population = [graph.nodes[i]['Population'] for i in graph.nodes()]    \n",
    "L = math.ceil((1-deviation/2)*total_population/k)\n",
    "U = math.floor((1+deviation/2)*total_population/k)\n",
    "print(\"Using L =\",L,\"and U =\",U,\"and k =\",k)\n",
    "sigma = 0.1\n",
    "DG = nx.DiGraph(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = gp.Model()\n",
    "x = m.addVars(graph.nodes, k, vtype = GRB.BINARY)\n",
    "y = m.addVars(graph.edges, vtype = GRB.BINARY)\n",
    "z = m.addVars(k, vtype = GRB.CONTINUOUS)\n",
    "alpha = 0.5 # EDIT THESE TO CHANGE IMPORTANCE OF OBJECTIVE FUNCTION\n",
    "beta = 0.5\n",
    "\n",
    "m.setObjective(alpha * gp.quicksum(y[u,v] for u,v in graph.edges) + beta * gp.quicksum(z[j] for j in range(k)), GRB.MINIMIZE)\n",
    "\n",
    "m.addConstrs(gp.quicksum(x[i,j] for j in range(k)) == 1 for i in graph.nodes)\n",
    "\n",
    "m.addConstrs(gp.quicksum(x[i,j] * graph.nodes[i]['population'] for i in graph.nodes) >= L for j in range(k))\n",
    "m.addConstrs(gp.quicksum(x[i,j] * graph.nodes[i]['population'] for i in graph.nodes) <= U for j in range(k))\n",
    "\n",
    "m.addConstrs(z[j] >= gp.quicksum(x[i, j] * graph.nodes[i]['num_republicans'] for i in graph.nodes) - \n",
    "             gp.quicksum(x[i, j] * graph.nodes[i]['num_democrats'] for i in graph.nodes) for j in range(k))\n",
    "m.addConstrs(z[j] >= gp.quicksum(x[i, j] * graph.nodes[i]['num_democrats'] for i in graph.nodes) - \n",
    "             gp.quicksum(x[i, j] * graph.nodes[i]['num_republicans'] for i in graph.nodes) for j in range(k))\n",
    "\n",
    "\n",
    "# add constraints saying that edge {i,j} is cut if i is assigned to district v but j is not.\n",
    "m.addConstrs( x[i,v] - x[j,v] <= y[i,j] for i,j in graph.edges for v in range(k))\n",
    "\n",
    "r = m.addVars(graph.nodes, k, vtype=GRB.BINARY)\n",
    "\n",
    "# Add flow variables: f[u,v] = amount of flow sent across arc uv \n",
    "#  Flows are sent across arcs of the directed version of G which we call DG\n",
    "import networkx as nx\n",
    "DG = nx.DiGraph(graph) # directed version of G\n",
    "f = m.addVars(DG.edges, vtype=GRB.CONTINUOUS)\n",
    "# The big-M proposed by Hojny et al.\n",
    "M = graph.number_of_nodes() - k + 1\n",
    "\n",
    "# Each district j should have one root\n",
    "m.addConstrs( gp.quicksum( r[i,j] for i in DG.nodes) == 1 for j in range(k) )\n",
    "\n",
    "# If node i is not assigned to district j, then it cannot be its root\n",
    "m.addConstrs( r[i,j] <= x[i,j] for i in DG.nodes for j in range(k) )  \n",
    "\n",
    "# if not a root, consume some flow.\n",
    "# if a root, only send out (so much) flow.\n",
    "m.addConstrs( gp.quicksum( f[u,v] - f[v,u] for u in DG.neighbors(v) ) >= 1 - M * gp.quicksum( r[v,j] for j in range(k)) for v in graph.nodes)\n",
    "\n",
    "# do not send flow across cut edges\n",
    "m.addConstrs( f[i,j] + f[j,i] <= M * (1 - y[i,j]) for (i,j) in graph.edges )\n",
    "m.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the districts and their populations\n",
    "districts = [ [i for i in graph.nodes if x[i,j].x > 0.5] for j in range(k)]\n",
    "district_counties = [ [ graph.nodes[i]['county'] for i in districts[j] ] for j in range(k)]\n",
    "district_populations = [ sum(graph.nodes[i][\"population\"] for i in districts[j]) for j in range(k) ]\n",
    "\n",
    "# print district info\n",
    "for j in range(k):\n",
    "    print(\"District\",j,\"has population\",district_populations[j],\"and contains counties\",district_counties[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which district is each county assigned to?\n",
    "assignment = [ -1 for u in graph.nodes ]\n",
    "    \n",
    "# for each district j\n",
    "for j in range(len(districts)):\n",
    "    \n",
    "    # for each node i in this district\n",
    "    for i in districts[j]:\n",
    "        \n",
    "        # What is its GEOID?\n",
    "        geoID = graph.nodes[i][\"OBJECTID\"]\n",
    "        \n",
    "        # Need to find this GEOID in the dataframe\n",
    "        for u in graph.nodes:\n",
    "            if geoID == data['OBJECTID'][u]: # Found it\n",
    "                assignment[u] = j # Node u from the dataframe should be assigned to district j\n",
    "\n",
    "# Now add the assignments to a column of the dataframe and map it\n",
    "data['assignment'] = assignment\n",
    "my_fig = data.plot(column='assignment').get_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignments = {i: j for i in graph.nodes for j in range(k) if x[i, j].X > 0.5}\n",
    "\n",
    "# Initialize counters for each district\n",
    "total_democrats = {j: 0 for j in range(k)}\n",
    "total_republicans = {j: 0 for j in range(k)}\n",
    "total_voters = {j: 0 for j in range(k)}\n",
    "\n",
    "# Sum up the numbers based on assignments\n",
    "for i in graph.nodes:\n",
    "    district_assigned = assignments[i]\n",
    "    total_democrats[district_assigned] += graph.nodes[i]['num_democrats']\n",
    "    total_republicans[district_assigned] += graph.nodes[i]['num_republicans']\n",
    "    total_voters[district_assigned] += graph.nodes[i]['num_democrats'] + graph.nodes[i]['num_republicans']\n",
    "\n",
    "# Calculate proportions for each district\n",
    "proportions = {}\n",
    "for j in range(k):\n",
    "    if total_voters[j] > 0:  # Prevent division by zero\n",
    "        sum_dem = total_democrats[j]\n",
    "        sum_rep = total_republicans[j]\n",
    "        sum_total = total_voters[j]\n",
    "        prop_democrats = total_democrats[j] / total_voters[j]\n",
    "        prop_republicans = total_republicans[j] / total_voters[j]\n",
    "        proportions[j] = {'Democrats': prop_democrats, 'Republicans': prop_republicans}\n",
    "        difference = prop_democrats / prop_republicans\n",
    "    else:\n",
    "        proportions[j] = {'Democrats': 0, 'Republicans': 0}\n",
    "\n",
    "# Output the proportions\n",
    "for j in proportions:\n",
    "    print(f\"District {j}: Democrats: {proportions[j]['Democrats']:.2f}, Republicans: {proportions[j]['Republicans']:.2f}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
